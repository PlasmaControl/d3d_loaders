{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a2db115",
   "metadata": {},
   "source": [
    "# Using d3d_loader to access D3D data\n",
    "\n",
    "The `d3d_loader` class implements a [pytorch Dataset](https://pytorch.org/docs/stable/data.html#map-style-datasets) that can be used to load D3D data, stored on traverse, for Machine Learning. \n",
    "\n",
    "\n",
    "From a user perspective, the `d3d_loader` lines up groups `1d` and `2d` signals over the same time interval and using a common sampling frequency. As a dataset, it can be used to iterate over this group of signals as is done in routine machine learning tasks\n",
    "\n",
    "The example below illustrates how to instantiate the `d3d_loader` and access multiple signals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d6f3940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/rkube/repos/d3d_loaders\")\n",
    "from d3d_loaders.d3d_loaders import D3D_dataset\n",
    "from os.path import join\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(filename=\"d3d_loader.log\", level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48cb6bb",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "To setup the dataloader we need to define a shot of interest and the time interval. We also need to define the desired sampling time on which all signals will be sub-samples. Additionally, we can load immediately load data on the gpu be specifying a device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d531ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shotnr = 169113\n",
    "# Define interval for the signals\n",
    "t0 = 0.001      \n",
    "t1 = 4000.0\n",
    "# Define a sampling time. This must be smaller than the sampling frequency on which the data was collected.\n",
    "t_sample = 1.0 \n",
    "# Define the GPU as the device on which to store the data\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Store variable in dictionary to pass to loading functions\n",
    "t_params = {\n",
    "    \"tstart\" : t0,\n",
    "    \"tend\"   : t1,\n",
    "    \"tsample\": t_sample\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b578f4",
   "metadata": {},
   "source": [
    "Next we want to specify a list of predictor and target signals. Typically these signals will be used as\n",
    "`model(predictor) = target`. For prediction tasks, some time series should be shifted into the future to satisfy causality. Time shifts can be defined for each predictor and target signal individually using the `shift_target` dictionary. The keys correspond to signal names and the values correspond to a time shift in milliseconds.\n",
    "\n",
    "\n",
    "Here we use `pinj`, `neut`, and `ae_prob` as predictors. The first two signals are just the data loaded from `hdf5` files. The `ae_prob` signal is constructed from the ECE data through the RCN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cef338c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = D3D_dataset(shotnr, t_params,\n",
    "                 predictors=[\"pinj\", \"neut\", \"ae_prob\"],\n",
    "                 targets=[\"ae_prob_delta\"],\n",
    "                 shift_target={\"ae_prob_delta\": 100.0},\n",
    "                 device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26824d9",
   "metadata": {},
   "source": [
    "Once the dataset is instantiated, the `predictor` and `targets` signals are available as [`torch.tensor`](https://pytorch.org/docs/stable/tensors.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba1c07f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pinj': signal_1d(tensor([[-1.7243],\n",
       "         [-1.7243],\n",
       "         [-1.7243],\n",
       "         ...,\n",
       "         [-0.6110],\n",
       "         [-0.5756],\n",
       "         [-0.5817]], device='cuda:0'),\n",
       " 'neut': signal_1d(tensor([[-1.1213],\n",
       "         [-0.9802],\n",
       "         [-0.6800],\n",
       "         ...,\n",
       "         [-0.9932],\n",
       "         [-0.6994],\n",
       "         [-0.9071]], device='cuda:0'),\n",
       " 'ae_prob': signal_1d(tensor([[-0.5361, -0.4713, -0.5580, -0.5282, -0.4688],\n",
       "         [-0.5552, -0.5045, -0.5606, -0.5465, -0.5136],\n",
       "         [-0.5714, -0.5365, -0.5582, -0.5660, -0.5408],\n",
       "         ...,\n",
       "         [-0.5808, -0.3281, -0.2933,  0.1483, -0.2929],\n",
       "         [-0.5810, -0.3023, -0.2971,  0.1564, -0.2804],\n",
       "         [-0.5828, -0.2705, -0.2981,  0.1742, -0.2535]], device='cuda:0')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3da060bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ae_prob_delta': signal_1d(tensor([[-0.0339, -0.0120, -0.0196, -0.0228, -0.0230],\n",
       "         [-0.0497, -0.0067, -0.0298, -0.0250, -0.0404],\n",
       "         [-0.0613, -0.0042, -0.0491, -0.0298, -0.0720],\n",
       "         ...,\n",
       "         [-0.0173, -0.2163, -0.1291, -0.1429,  0.2643],\n",
       "         [-0.0111, -0.2856, -0.1328, -0.1607,  0.2149],\n",
       "         [-0.0033, -0.3649, -0.1427, -0.2090,  0.1258]], device='cuda:0')}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0703bc77",
   "metadata": {},
   "source": [
    "Accessing predictor and target data follows pytorch conventions. We can index the dataset to get a tuple of all`(predictor, target)` samples.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7922979c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "pred, target = ds[0]\n",
    "print(pred.shape, target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959da2da",
   "metadata": {},
   "source": [
    "## DataLoaders\n",
    "As a dataset, the `d3d_loader` can easily be used in [`DataLoaders`](https://pytorch.org/docs/stable/data.html#module-torch.utils.data). The code below illustrates usage.\n",
    "Features, such as shuffling, batch_sizes, and multi-threading are supported through this interface.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13228ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a dataloader which loads 5 samples per call\n",
    "loader = DataLoader(ds, batch_size=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6da3d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([37, 7]) torch.Size([37, 5])\n"
     ]
    }
   ],
   "source": [
    "# Get the first item and print the sizes\n",
    "pred, target = next(iter(loader))\n",
    "print(pred.shape, target.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4c368f49471945f7a22d09637ac0c0a3fc9b387e8d0bf26b282b3740e2c9027"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
